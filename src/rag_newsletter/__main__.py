# =============================================================================
# RAG Newsletter - Point d'entr√©e principal
# =============================================================================
# Script principal pour l'ingestion et la gestion des documents RAG
# avec optimisations Apple Silicon et int√©gration SharePoint.
# =============================================================================

import argparse
import os
import pathlib

from dotenv import load_dotenv
from loguru import logger

from rag_newsletter.ingestion.rag_ingestion import OptimizedRAGIngestionService
from rag_newsletter.ingestion.sharepoint_client import make_client_from_env

# Configuration du logging avec loguru
logger.remove()  # Supprimer le handler par d√©faut
logger.add(
    lambda msg: print(msg, end=""),
    format=(
        "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
        "<level>{level: <8}</level> | "
        "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
        "<level>{message}</level>"
    ),
    level="INFO",
)


def main():
    """
    Point d'entr√©e principal du script RAG Newsletter.

    Ce script permet de g√©rer l'ingestion et la recherche de documents
    avec optimisations Apple Silicon et int√©gration SharePoint.

    Fonctionnalit√©s disponibles:
    - T√©l√©chargement de documents depuis SharePoint
    - Ingestion de documents dans le vector store Qdrant
    - Recherche s√©mantique avec MMR (Maximum Marginal Relevance)
    - Comparaison de documents
    - Filtrage par documents sp√©cifiques
    - Statistiques de la collection

    Exemples d'utilisation:
        python -m rag_newsletter --download --max 50                    # T√©l√©charger 50 documents
        python -m rag_newsletter --ingest --batch-size 5               # Ing√©rer avec des lots de 5
        python -m rag_newsletter --search "sustainability strategy"    # Rechercher des documents
        python -m rag_newsletter --search-mmr --lambda 0.5             # Recherche MMR avec diversit√©
        python -m rag_newsletter --compare doc1.pdf doc2.pdf           # Comparer deux documents
        python -m rag_newsletter --stats                                # Afficher les statistiques
    """
    # Charger les variables d'environnement depuis .env
    load_dotenv()

    # Configuration du parser d'arguments
    p = argparse.ArgumentParser(
        description="RAG Newsletter Optimis√© - Importateur SharePoint avec MCDSE-2B + MLX"
    )

    # Arguments de configuration SharePoint
    p.add_argument(
        "--drive",
        default=os.getenv("SP_DRIVE_NAME", "Documents"),
        help="Nom du drive SharePoint √† utiliser",
    )
    p.add_argument("--drive-id", help="ID du drive SharePoint (si sp√©cifique)")
    p.add_argument(
        "--max", type=int, default=100, help="Nombre maximum de documents √† traiter"
    )

    # Arguments d'actions principales
    p.add_argument(
        "--download",
        action="store_true",
        help="T√©l√©charger les fichiers depuis SharePoint",
    )
    p.add_argument(
        "--ingest",
        action="store_true",
        help="Ing√©rer les fichiers dans le vector store optimis√©",
    )
    p.add_argument("--search", type=str, help="Rechercher dans les documents index√©s")
    p.add_argument(
        "--search-mmr",
        action="store_true",
        help="Utiliser la recherche MMR (Maximum Marginal Relevance)",
    )
    p.add_argument(
        "--lambda",
        type=float,
        default=0.7,
        help="Facteur de diversit√© pour MMR (0.0-1.0)",
    )
    p.add_argument(
        "--compare", nargs=2, metavar=("DOC1", "DOC2"), help="Comparer deux documents"
    )
    p.add_argument(
        "--filter-docs",
        nargs="+",
        help="Filtrer la recherche √† des documents sp√©cifiques",
    )
    p.add_argument(
        "--list-drives",
        action="store_true",
        help="Lister les drives SharePoint disponibles",
    )
    p.add_argument(
        "--stats",
        action="store_true",
        help="Afficher les statistiques de la collection",
    )

    # Arguments de configuration
    p.add_argument(
        "--outdir",
        default="downloads",
        help="R√©pertoire de sortie pour les t√©l√©chargements",
    )
    p.add_argument(
        "--extensions",
        nargs="+",
        default=[".pdf", ".docx", ".pptx", ".xlsx", ".txt"],
        help="Extensions de fichiers √† importer",
    )
    p.add_argument(
        "--qdrant-url", default="http://localhost:6333", help="URL du serveur Qdrant"
    )
    p.add_argument(
        "--collection", default="rag_newsletter", help="Nom de la collection Qdrant"
    )
    p.add_argument(
        "--model", default="marco/mcdse-2b-v1", help="Mod√®le d'embedding √† utiliser"
    )
    p.add_argument(
        "--no-binary-quantization",
        action="store_true",
        help="D√©sactiver la quantization binaire",
    )
    p.add_argument(
        "--batch-size", type=int, default=10, help="Taille des lots pour l'ingestion"
    )

    # Parser les arguments
    a = p.parse_args()

    try:
        # Initialiser le service RAG optimis√© avec les param√®tres fournis
        rag_service = OptimizedRAGIngestionService(
            qdrant_url=a.qdrant_url,
            collection_name=a.collection,
            model_name=a.model,
            use_binary_quantization=not a.no_binary_quantization,
            use_mmr=True,  # Activer MMR pour la diversit√© des r√©sultats
        )

        # Afficher les informations de configuration
        logger.info("üöÄ RAG Newsletter Optimis√© - Configuration:")
        logger.info(f"   üì± Mod√®le: {a.model}")
        logger.info(f"   üîó Qdrant: {a.qdrant_url}")
        logger.info(f"   üìö Collection: {a.collection}")
        logger.info(f"   ‚ö° Binary Quantization: {not a.no_binary_quantization}")
        logger.info("   üéØ MMR Search: True")
        logger.info("   üçé Optimis√© pour Apple Silicon M4")

        # Gestion des drives SharePoint
        if a.list_drives or a.download or a.ingest:
            # Initialiser le client SharePoint avec les variables d'environnement
            sp = make_client_from_env()

            # Lister les drives SharePoint disponibles
            if a.list_drives:
                drives = sp.list_drives()
                logger.info(f"üìÅ Drives disponibles ({len(drives)}):")
                for i, drive in enumerate(drives, 1):
                    logger.info(f"   {i}. {drive['name']} (ID: {drive['id']})")
                return

            # R√©soudre l'ID du drive SharePoint
            drive_id = a.drive_id
            if not drive_id:
                drive_id = sp.find_drive_id(a.drive)
                if not drive_id:
                    raise SystemExit(
                        f"Drive '{a.drive}' introuvable. Utilise --drive-id ou ajuste SP_DRIVE_NAME."
                    )

            # Lister les fichiers seulement si n√©cessaire
            if a.download or a.ingest:
                files = sp.list_files(drive_id, exts=tuple(a.extensions))
                logger.info(f"üìÑ Fichiers trouv√©s: {len(files)}")

                # Afficher les fichiers (limit√©s par --max)
                for f in files[: a.max]:
                    size_mb = round(f.get("size", 0) / (1024 * 1024), 2)
                    logger.info(
                        f"   - {f['name']}  | {f['last_modified']} | {size_mb} MB"
                    )

            # T√©l√©charger les fichiers depuis SharePoint
            if a.download and files:
                logger.info("\nüì• T√©l√©chargement des fichiers...")
                downloaded = sp.download_multiple(
                    drive_id=drive_id,
                    files=files,
                    output_dir=a.outdir,  # R√©pertoire de sortie
                    max_files=a.max,  # Limiter par --max
                )

                # Afficher le r√©sum√© du t√©l√©chargement
                summary = sp.get_download_summary(downloaded)
                logger.info("\n‚úÖ R√©sum√© du t√©l√©chargement:")
                logger.info(f"   üìÅ Fichiers t√©l√©charg√©s: {summary['total_files']}")
                logger.info(f"   üíæ Taille totale: {summary['total_size_mb']} MB")
                logger.info(f"   üìã Extensions: {summary['extensions']}")
                logger.info(f"   üìÇ R√©pertoire: {pathlib.Path(a.outdir).absolute()}")

        # Ingestion optimis√©e des documents dans le vector store
        if a.ingest:
            logger.info("\nüöÄ Ingestion optimis√©e des documents...")

            # Utiliser les fichiers t√©l√©charg√©s ou chercher dans le r√©pertoire
            if a.download and "downloaded" in locals():
                # Utiliser les fichiers qui viennent d'√™tre t√©l√©charg√©s
                file_paths = [f["local_path"] for f in downloaded]
                logger.info(
                    f"üìÅ Utilisation des {len(file_paths)} fichiers t√©l√©charg√©s"
                )
            else:
                # Chercher les fichiers PDF dans le r√©pertoire
                download_path = pathlib.Path(a.outdir)
                file_paths = list(download_path.glob("*.pdf"))
                file_paths = [str(f) for f in file_paths]
                logger.info(
                    f"üìÅ Utilisation des {len(file_paths)} fichiers trouv√©s dans {a.outdir}"
                )

            if not file_paths:
                logger.warning("‚ö†Ô∏è  Aucun fichier √† ing√©rer")
                return 1

            # Ing√©rer les documents avec le service RAG optimis√©
            result = rag_service.ingest_documents(
                file_paths=file_paths, batch_size=a.batch_size
            )

            # Afficher le r√©sum√© de l'ingestion
            logger.info("\nüéâ R√©sultat de l'ingestion optimis√©e:")
            logger.info(f"   üìä Statut: {result['status']}")
            if result["status"] == "success":
                logger.info(f"   üìÑ Pages trait√©es: {result['total_chunks']}")
                logger.info(f"   üìÅ Fichiers trait√©s: {result['processed_files']}")
                logger.info(f"   üî¢ IDs vectoriels: {result['vector_ids']}")
                logger.info(f"   ‚ö° Optimisations: {result['optimizations']}")
            else:
                logger.error(f"   ‚ùå Erreur: {result['message']}")

        # Recherche optimis√©e dans les documents index√©s
        if a.search:
            logger.info(f"\nüîç Recherche optimis√©e: '{a.search}'")

            # D√©terminer le type de recherche selon les param√®tres
            if a.search_mmr:
                logger.info(f"üéØ Mode MMR avec lambda={getattr(a, 'lambda', 0.7)}")
                search_results = rag_service.search(
                    query=a.search,
                    k=5,
                    use_mmr=True,
                    lambda_mult=getattr(a, "lambda", 0.7),
                )
            elif a.filter_docs:
                logger.info(f"üìã Recherche filtr√©e aux documents: {a.filter_docs}")
                search_results = rag_service.search_with_document_filter(
                    query=a.search, document_names=a.filter_docs, k=5
                )
            else:
                logger.info("üîç Recherche HNSW standard")
                search_results = rag_service.search(query=a.search, k=5)

            # Afficher les r√©sultats de la recherche
            logger.info(f"\n‚úÖ R√©sultats trouv√©s: {len(search_results)}")
            for i, result in enumerate(search_results, 1):
                logger.info(f"\n--- R√©sultat {i} ---")
                logger.info(f"   üìä Score: {result['score']:.3f}")
                logger.info(f"   üìÑ Source: {result['source']}")
                logger.info(f"   üìÉ Page: {result['page']}")
                logger.info(f"   üî¢ Chunk: {result['chunk_index']}")
                logger.info(f"   üìù Contenu: {result['content'][:200]}...")

        # Comparaison de documents sp√©cifiques
        if a.compare:
            doc1, doc2 = a.compare
            logger.info(f"\nüîÑ Comparaison: {doc1} vs {doc2}")
            logger.info(f"   üîç Requ√™te: '{a.search or 'Analyse g√©n√©rale'}'")

            # Effectuer la comparaison des documents
            comparison_results = rag_service.compare_documents(
                query=a.search or "Analyse g√©n√©rale",
                document_pairs=[(doc1, doc2)],
                k_per_doc=3,
            )

            for comparison_key, results in comparison_results.items():
                logger.info(f"\nüìä R√©sultats de comparaison: {comparison_key}")
                logger.info(f"   üìÑ {doc1}: {len(results[doc1])} r√©sultats")
                logger.info(f"   üìÑ {doc2}: {len(results[doc2])} r√©sultats")

                if results["similarities"]:
                    logger.info(f"   ‚úÖ Similarit√©s: {results['similarities']}")
                if results["differences"]:
                    logger.info(f"   ‚ö†Ô∏è  Diff√©rences: {results['differences']}")

        # Statistiques de la collection Qdrant
        if a.stats:
            logger.info("\nüìä Statistiques de la collection:")
            stats = rag_service.get_collection_stats()
            logger.info(f"   üìö Collection: {stats['collection_name']}")
            logger.info(f"   üîó URL: {stats['qdrant_url']}")
            logger.info(f"   ü§ñ Mod√®le: {stats['model']}")
            logger.info(f"   ‚ö° Optimisations: {stats['optimizations']}")

            if stats.get("collection_info"):
                info = stats["collection_info"]
                logger.info(f"   üìÑ Vecteurs: {info.get('vectors_count', 'N/A')}")
                logger.info(f"   üìä Points: {info.get('points_count', 'N/A')}")
                logger.info(f"   üìà Segments: {info.get('segments_count', 'N/A')}")
                logger.info(f"   ‚úÖ Statut: {info.get('status', 'N/A')}")

    except Exception as e:
        logger.error(f"‚ùå Erreur: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
